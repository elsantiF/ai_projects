{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_kwargs = { 'batch_size': 32 }\n",
    "if use_cuda:\n",
    "    dataloader_kwargs.update({ 'num_workers': 4, 'pin_memory': True, 'shuffle': True })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, generator=torch.Generator(device), **dataloader_kwargs)\n",
    "test_loader = DataLoader(test_dataset, generator=torch.Generator(device), **dataloader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(\n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        kernel_size: int = 3, \n",
    "        padding: int = 1) -> nn.Sequential:\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Dropout(0.2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10Model, self).__init__()\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            conv_block(3, 64),\n",
    "            conv_block(64, 128),\n",
    "            conv_block(128, 256),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.seq(x)\n",
    "    \n",
    "model = CIFAR10Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2199114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "critrion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, device: torch.device, train_loader: DataLoader, optimizer: optim.Optimizer, epoch: int):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data: torch.Tensor = data.to(device)\n",
    "        target: torch.Tensor = target.to(device)\n",
    "\n",
    "        start = time.perf_counter_ns()\n",
    "        optimizer.zero_grad()\n",
    "        output: torch.Tensor = model(data)\n",
    "        loss: torch.Tensor = critrion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        end = (time.perf_counter_ns() - start) / 1000.0 / 1000.0\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\\tTime: {end:.3f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, device: torch.device, test_loader: DataLoader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data: torch.Tensor = data.to(device)\n",
    "            target: torch.Tensor = target.to(device)\n",
    "\n",
    "            output: torch.Tensor = model(data)\n",
    "            test_loss += critrion(output, target).item()\n",
    "            pred: torch.Tensor = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.150441\tTime: 161.934ms\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 0.074412\tTime: 12.341ms\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.009397\tTime: 12.131ms\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 0.074180\tTime: 15.177ms\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.076039\tTime: 13.885ms\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.024151\tTime: 12.086ms\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.005513\tTime: 15.406ms\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.032826\tTime: 12.153ms\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.024031\tTime: 12.348ms\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.134738\tTime: 12.228ms\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.056724\tTime: 12.371ms\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.078589\tTime: 13.049ms\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.107099\tTime: 12.290ms\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.037980\tTime: 12.164ms\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.079989\tTime: 12.379ms\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.080505\tTime: 12.569ms\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 8843/10000 (88%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.060409\tTime: 160.616ms\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.045843\tTime: 14.825ms\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.093588\tTime: 13.437ms\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.056305\tTime: 14.986ms\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.079146\tTime: 15.753ms\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.035760\tTime: 13.170ms\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.239722\tTime: 14.933ms\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.374281\tTime: 12.802ms\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.058572\tTime: 14.305ms\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.034940\tTime: 12.659ms\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.036819\tTime: 12.711ms\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.012617\tTime: 12.515ms\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.036680\tTime: 12.294ms\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.021267\tTime: 12.336ms\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.108424\tTime: 17.814ms\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.024216\tTime: 12.239ms\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 8846/10000 (88%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.067534\tTime: 160.282ms\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.006789\tTime: 12.579ms\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.173475\tTime: 15.031ms\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.038231\tTime: 14.842ms\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.108639\tTime: 12.615ms\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.031520\tTime: 13.292ms\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.146271\tTime: 12.068ms\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.067582\tTime: 12.361ms\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.119182\tTime: 13.275ms\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.016695\tTime: 12.536ms\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.008905\tTime: 14.606ms\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.037706\tTime: 12.308ms\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.110455\tTime: 12.377ms\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.078874\tTime: 12.528ms\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.043255\tTime: 12.242ms\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.028862\tTime: 15.123ms\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 8870/10000 (89%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.132636\tTime: 159.721ms\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.264686\tTime: 13.366ms\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.035248\tTime: 15.191ms\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.116590\tTime: 12.269ms\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.227927\tTime: 14.539ms\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.041963\tTime: 15.610ms\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.146612\tTime: 12.322ms\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.035992\tTime: 12.357ms\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.032374\tTime: 12.880ms\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 0.059636\tTime: 12.508ms\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.015277\tTime: 12.346ms\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.053400\tTime: 11.951ms\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.033745\tTime: 12.466ms\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.075542\tTime: 12.316ms\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.030297\tTime: 12.592ms\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.181092\tTime: 15.429ms\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 8885/10000 (89%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.020363\tTime: 161.791ms\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 0.015150\tTime: 12.692ms\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.100089\tTime: 14.575ms\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.017205\tTime: 12.154ms\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.060749\tTime: 12.218ms\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.054968\tTime: 12.661ms\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.058138\tTime: 14.906ms\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 0.127935\tTime: 12.171ms\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.039328\tTime: 12.227ms\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 0.073788\tTime: 12.181ms\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.116535\tTime: 12.445ms\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 0.043704\tTime: 12.621ms\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.054499\tTime: 15.098ms\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 0.055806\tTime: 13.599ms\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.029992\tTime: 12.754ms\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.088123\tTime: 12.735ms\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 8892/10000 (89%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.280671\tTime: 161.344ms\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 0.196211\tTime: 12.325ms\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.046163\tTime: 12.294ms\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 0.042599\tTime: 12.300ms\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.025787\tTime: 12.766ms\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.093469\tTime: 12.176ms\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.079887\tTime: 12.169ms\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 0.093211\tTime: 12.646ms\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.027259\tTime: 14.902ms\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 0.124621\tTime: 15.720ms\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.063640\tTime: 13.207ms\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 0.025741\tTime: 12.419ms\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.155269\tTime: 14.451ms\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 0.107568\tTime: 12.463ms\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.013625\tTime: 13.360ms\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.028373\tTime: 15.502ms\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 8894/10000 (89%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.053757\tTime: 159.738ms\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 0.045994\tTime: 13.528ms\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.016782\tTime: 12.684ms\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 0.069200\tTime: 15.430ms\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.019527\tTime: 12.497ms\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.172912\tTime: 18.366ms\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.163438\tTime: 12.491ms\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 0.062076\tTime: 12.175ms\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.114041\tTime: 14.970ms\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 0.061467\tTime: 15.431ms\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.036713\tTime: 14.366ms\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 0.029999\tTime: 12.449ms\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.146725\tTime: 12.190ms\n",
      "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 0.114726\tTime: 12.300ms\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.071850\tTime: 12.153ms\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.072363\tTime: 12.285ms\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 8851/10000 (89%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.019193\tTime: 160.366ms\n",
      "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 0.081836\tTime: 12.323ms\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.170495\tTime: 12.503ms\n",
      "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 0.033135\tTime: 15.745ms\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.084212\tTime: 12.924ms\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.081668\tTime: 12.335ms\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.028355\tTime: 13.585ms\n",
      "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 0.037580\tTime: 13.256ms\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.039866\tTime: 12.825ms\n",
      "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 0.046676\tTime: 14.959ms\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.069010\tTime: 14.465ms\n",
      "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 0.011707\tTime: 12.665ms\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.038667\tTime: 12.304ms\n",
      "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 0.015579\tTime: 15.142ms\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.013338\tTime: 12.454ms\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.014767\tTime: 12.748ms\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 8895/10000 (89%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.036095\tTime: 161.615ms\n",
      "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 0.033733\tTime: 12.065ms\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.055635\tTime: 12.145ms\n",
      "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 0.014665\tTime: 12.211ms\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.156786\tTime: 15.569ms\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.036163\tTime: 12.128ms\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.027674\tTime: 12.997ms\n",
      "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 0.048230\tTime: 12.995ms\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.118214\tTime: 12.234ms\n",
      "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 0.069591\tTime: 11.998ms\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.057494\tTime: 14.574ms\n",
      "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 0.075258\tTime: 12.994ms\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.151172\tTime: 15.016ms\n",
      "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 0.070484\tTime: 12.575ms\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.024971\tTime: 13.161ms\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.069136\tTime: 12.148ms\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 8887/10000 (89%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.094094\tTime: 162.710ms\n",
      "Train Epoch: 10 [3200/50000 (6%)]\tLoss: 0.018185\tTime: 15.350ms\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.032133\tTime: 17.083ms\n",
      "Train Epoch: 10 [9600/50000 (19%)]\tLoss: 0.065642\tTime: 13.981ms\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.053406\tTime: 15.599ms\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.019077\tTime: 14.709ms\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.076538\tTime: 17.246ms\n",
      "Train Epoch: 10 [22400/50000 (45%)]\tLoss: 0.026863\tTime: 16.248ms\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.089064\tTime: 14.090ms\n",
      "Train Epoch: 10 [28800/50000 (58%)]\tLoss: 0.052943\tTime: 16.601ms\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.099411\tTime: 13.563ms\n",
      "Train Epoch: 10 [35200/50000 (70%)]\tLoss: 0.007421\tTime: 15.592ms\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.058433\tTime: 16.198ms\n",
      "Train Epoch: 10 [41600/50000 (83%)]\tLoss: 0.070538\tTime: 15.948ms\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.039875\tTime: 14.930ms\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.061905\tTime: 14.882ms\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 8898/10000 (89%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.039003\tTime: 161.601ms\n",
      "Train Epoch: 11 [3200/50000 (6%)]\tLoss: 0.060104\tTime: 20.588ms\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.066890\tTime: 14.915ms\n",
      "Train Epoch: 11 [9600/50000 (19%)]\tLoss: 0.020974\tTime: 16.030ms\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.045426\tTime: 15.093ms\n",
      "Train Epoch: 11 [16000/50000 (32%)]\tLoss: 0.128122\tTime: 14.686ms\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.116095\tTime: 15.439ms\n",
      "Train Epoch: 11 [22400/50000 (45%)]\tLoss: 0.137301\tTime: 15.094ms\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.031559\tTime: 13.319ms\n",
      "Train Epoch: 11 [28800/50000 (58%)]\tLoss: 0.081524\tTime: 14.821ms\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.115852\tTime: 16.412ms\n",
      "Train Epoch: 11 [35200/50000 (70%)]\tLoss: 0.022561\tTime: 14.694ms\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.027017\tTime: 15.777ms\n",
      "Train Epoch: 11 [41600/50000 (83%)]\tLoss: 0.011967\tTime: 13.039ms\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.050456\tTime: 14.953ms\n",
      "Train Epoch: 11 [48000/50000 (96%)]\tLoss: 0.025849\tTime: 12.438ms\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 8876/10000 (89%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.015289\tTime: 159.869ms\n",
      "Train Epoch: 12 [3200/50000 (6%)]\tLoss: 0.128932\tTime: 13.279ms\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 0.016106\tTime: 16.441ms\n",
      "Train Epoch: 12 [9600/50000 (19%)]\tLoss: 0.088089\tTime: 13.262ms\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.064975\tTime: 15.532ms\n",
      "Train Epoch: 12 [16000/50000 (32%)]\tLoss: 0.034773\tTime: 14.535ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     train(model, device, train_loader, optimizer, epoch)\n\u001b[0;32m      4\u001b[0m     test(model, device, test_loader)\n\u001b[0;32m      5\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model: nn\u001b[38;5;241m.\u001b[39mModule, device: torch\u001b[38;5;241m.\u001b[39mdevice, train_loader: DataLoader, optimizer: optim\u001b[38;5;241m.\u001b[39mOptimizer, epoch: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      5\u001b[0m         data: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m         target: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\santi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:626\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[0;32m    627\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\santi\\anaconda3\\Lib\\site-packages\\torch\\autograd\\profiler.py:688\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_enter_new(\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    690\u001b[0m     )\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\santi\\anaconda3\\Lib\\site-packages\\torch\\_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[1;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "File \u001b[1;32mc:\\Users\\santi\\anaconda3\\Lib\\site-packages\\torch\\utils\\_device.py:79\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\santi\\anaconda3\\Lib\\site-packages\\torch\\_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[1;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(model.state_dict(), \"cifar10_20epochs.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
